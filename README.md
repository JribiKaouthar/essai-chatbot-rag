# ESSAI Chatbot (RAG) with TinyLlama and Streamlit

An intelligent chatbot designed for the **Higher School of Statistics and Information Analysis (ESSAI) in Tunis**.  
The chatbot leverages **Retrieval-Augmented Generation (RAG)** to answer user questions from institutional PDF documents.  
It uses **FAISS semantic search** with MiniLM embeddings for document retrieval, and **TinyLlama** as the local language model, all deployed inside a **Streamlit web interface**.

---

## ğŸš€ Features
- ğŸ“„ **PDF ingestion** â€“ load ESSAI documents with `PyPDFLoader`
- âœ‚ï¸ **Text chunking** â€“ split documents into manageable sections with LangChain
- ğŸ” **Vector search** â€“ FAISS index with `sentence-transformers/all-MiniLM-L6-v2`
- ğŸ¤– **TinyLlama model** â€“ local causal LM for response generation
- ğŸ§  **RAG pipeline** â€“ combine context retrieval + generative model
- ğŸ’¬ **Streamlit UI** â€“ clean chat interface with styled user and bot bubbles
- âš¡ **Optimized for CPU** â€“ runs on local machines without GPUs
- ğŸ”’ **.env configuration** â€“ easy setup without exposing secrets

---

## ğŸ“‚ Project Structure
essai-chatbot-rag/
â”‚â”€â”€ app.py # Main Streamlit app
â”‚â”€â”€ requirements.txt # Python dependencies
â”‚â”€â”€ .env.example # Example environment variables
â”‚â”€â”€ README.md # Project documentation
â”‚â”€â”€ .gitignore # Files and folders to ignore
â”‚
â”œâ”€â”€ src/ # (Optional) extra Python modules
â”œâ”€â”€ data/ # Place PDFs here (not committed)
â”‚ â””â”€â”€ README.md
â”œâ”€â”€ assets/ # Images, logos, icons
â”‚ â””â”€â”€ essai-logo.ico


---

## âš™ï¸ Installation

### 1. Clone the repository

git clone https://github.com/<your-username>/essai-chatbot-rag.git
cd essai-chatbot-rag

2. Create a virtual environment
python -m venv .venv
# Activate it
# Windows:
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

3. Install dependencies
pip install -r requirements.txt

4. Configure environment variables

Copy .env.example to .env:

cp .env.example .env   # macOS/Linux
copy .env.example .env # Windows


Edit .env with your actual paths (PDF folder, model folder, etc.).

ğŸ“š Models & Data

PDF documents â†’ place them in the data/ folder.

Language model (TinyLlama) â†’ download from Hugging Face and place in ./TinyLlama.
Example:

git clone https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0 TinyLlama

â–¶ï¸ Run the Application

Start the chatbot locally:

streamlit run app.py


Then open your browser at http://localhost:8501
.

ğŸ“Š Example Workflow

User asks: â€œWhat is ESSAI?â€

FAISS retrieves the most relevant sections from PDF documents.

TinyLlama generates a contextualized answer.

The answer is displayed in the chat interface with a friendly style.

ğŸ› ï¸ Technologies Used

Python

Streamlit

LangChain

FAISS

Hugging Face Transformers

TinyLlama

ğŸ“Œ Future Improvements

Deploy on the web (Streamlit Cloud or Hugging Face Spaces)

Add multilingual support (Arabic / French / English)

Enhance with larger LLMs (LLaMA 2, Mistral, etc.)

Integrate authentication for student/teacher access

ğŸ“ License

This project is licensed under the MIT License â€“ feel free to use and adapt.

ğŸ“§ Contact

Kaouthar Jribi
ğŸ“ Tunis, Tunisia
ğŸ“© jribikaouthar@yahoo.com

ğŸ”— linkedin.com/in/kaouthar-jribi


---

